{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevation Interpolation and Accuracy Assessment\n",
    "\n",
    "Logan Gall\n",
    "\n",
    "Attributions: ChatGPT, Laure Briol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import arcpy\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import os\n",
    "import random\n",
    "\n",
    "#location to current directory\n",
    "file_path = os.path.dirname(arcpy.mp.ArcGISProject('CURRENT').filePath)\n",
    "os.chdir(file_path)\n",
    "#absolute Path for geodatabase\n",
    "arcpy.env.workspace = file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database connection\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"gis5572\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Passwordd\",\n",
    "    host=\"35.188.97.184\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2703\n"
     ]
    }
   ],
   "source": [
    "#Select the table for our elevation data. Return shape as WKT\n",
    "sql_query = \"\"\"\n",
    "SELECT grid_code, ST_AsText(shape) AS WKT\n",
    "FROM dem_resampled_point;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "cur.execute(sql_query)\n",
    "\n",
    "# Fetch the results\n",
    "fetched_data = cur.fetchall()\n",
    "\n",
    "print(len(fetched_data))\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"5572Lab3.gdb\"  #Output geodatabase\n",
    "feature_class_name = \"ElevationPointRaw\" #Output data\n",
    "geometry_type = \"POINT\"\n",
    "\n",
    "#Spatial reference\n",
    "spatial_reference = arcpy.SpatialReference(26915)\n",
    "\n",
    "#Create empty feature class\n",
    "arcpy.CreateFeatureclass_management(output_path, feature_class_name, geometry_type, spatial_reference=spatial_reference)\n",
    "\n",
    "#Add fields to the feature class\n",
    "arcpy.AddField_management(f\"{output_path}/{feature_class_name}\", \"elevation\", \"LONG\")\n",
    "\n",
    "#Insert data into the feature class\n",
    "with arcpy.da.InsertCursor(f\"{output_path}/{feature_class_name}\", [\"elevation\", \"SHAPE@WKT\"]) as cursor:\n",
    "    for row in fetched_data:\n",
    "        #Inserts data assuming SQL return is in same order\n",
    "        cursor.insertRow(row)\n",
    "\n",
    "print(\"Data transfer to Feature Class is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 8:59:00 PM\",\"WARNING 000258: Output C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\5572Lab3\\\\database_connection\\\\postgres_connection.sde already exists\",\"Succeeded at Friday, March 15, 2024 8:59:11 PM (Elapsed Time: 11.06 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\5572Lab3\\\\database_connection\\\\postgres_connection.sde'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up Database Connection within Arc\n",
    "# Parameters for the database connection\n",
    "out_folder = arcpy.env.workspace + '\\\\database_connection'  # Folder where the .sde file will be stored\n",
    "out_nam = \"postgres_connection.sde\"  # Name of the .sde file to create\n",
    "\n",
    "# Database connection properties\n",
    "server = \"35.188.97.184\"  # Name or IP of the PostgreSQL server\n",
    "service = \"5432\"  # PostgreSQL port (default is 5432)\n",
    "database = \"gis5572\"  # Name of the database\n",
    "username = \"postgres\"\n",
    "password = \"Passwordd\"\n",
    "authentication_type = \"DATABASE_AUTH\"\n",
    "version = \"sde.DEFAULT\"\n",
    "\n",
    "#Create database connection file\n",
    "arcpy.management.CreateDatabaseConnection(\n",
    "    out_folder_path=out_folder,\n",
    "    out_name=out_nam,\n",
    "    database_platform=\"POSTGRESQL\",\n",
    "    instance=server,\n",
    "    account_authentication=\"DATABASE_AUTH\",\n",
    "    username=username,\n",
    "    password=password,\n",
    "    save_user_pass=\"SAVE_USERNAME\",\n",
    "    database=\"gis5572\",\n",
    "    schema=\"\",\n",
    "    version_type=\"TRANSACTIONAL\",\n",
    "    version=\"\",\n",
    "    date=None,\n",
    "    auth_type=\"\",\n",
    "    project_id=\"\",\n",
    "    default_dataset=\"\",\n",
    "    refresh_token='',\n",
    "    key_file=None,\n",
    "    role=\"\",\n",
    "    warehouse=\"\",\n",
    "    advanced_options=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "### Justification for Train/Test Split\n",
    "\n",
    "Using a larger dataset for training, like in a 90/10 split, helps with statistical significance. The more data we have to train the model, the more confident we can be about the patterns it learns and the predictions it makes. The larger training set allows the model to better understand and generalize the complex patterns in elevation data, making its predictions reliable. The large training set helps make it robust to noise and outliers. With 90% of the data used for training, the model has a better chance of identifying and learning to ignore or properly interpret significant changes in elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created subset feature classes\n"
     ]
    }
   ],
   "source": [
    "#path to feature class\n",
    "feature_class_path = \"\\\\5572Lab3.gdb\\\\ElevationPointRaw\"\n",
    "\n",
    "#Output path for the subset feature class\n",
    "output_feature_class = \"\\\\5572Lab3.gdb\\\\ElevationPoint10\" #Testing data\n",
    "output_feature_class2 = \"\\\\5572Lab3.gdb\\\\ElevationPoint90\" #Training data\n",
    "\n",
    "\n",
    "#Get the count of rows\n",
    "feature_count = arcpy.GetCount_management(feature_class_path)[0]\n",
    "\n",
    "#Calculate 10% of the total features\n",
    "subset_count = int(float(feature_count) * 0.1)\n",
    "\n",
    "#Generate a list of random indices\n",
    "random.seed = 0\n",
    "#list selecting points to be selected (list of objectID's)\n",
    "random_indices = random.sample(range(int(feature_count)), subset_count)\n",
    "\n",
    "#create a query to select these indices\n",
    "oids = [str(oid) for oid in random_indices]\n",
    "query = f\"OBJECTID IN ({','.join(oids)})\"\n",
    "query2 = f\"OBJECTID NOT IN ({','.join(oids)})\"\n",
    "\n",
    "#Select_analysis to create a new feature class with the subset\n",
    "arcpy.Select_analysis(feature_class_path, output_feature_class, query)\n",
    "arcpy.Select_analysis(feature_class_path, output_feature_class2, query2)\n",
    "\n",
    "print(f\"Created subset feature classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave one out interpolation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 8:59:20 PM\",\"Calculating Ordinary Kriging – Default\",\"Calculating Ordinary Kriging – Optimized\",\"Calculating Universal Kriging – Default\",\"Calculating Universal Kriging – Optimized\",\"Calculating Inverse Distance Weighted - Default\",\"Calculating Inverse Distance Weighted - Optimized\",\" \\n\",\"--------------------------------------------\",\"RANK | NAME\",\"--------------------------------------------\",\"\\n\",\"1    | Universal Kriging – Optimized\",\"\\n\",\"2    | Universal Kriging – Default\",\"\\n\",\"3    | Ordinary Kriging – Default\",\"\\n\",\"4    | Ordinary Kriging – Optimized\",\"\\n\",\"5    | Inverse Distance Weighted - Optimized\",\"\\n\",\"6    | Inverse Distance Weighted - Default\",\"--------------------------------------------\",\"Succeeded at Friday, March 15, 2024 8:59:29 PM (Elapsed Time: 8.25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\5572Lab3\\\\5572Lab3.gdb\\\\InterpolationExp'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leave one out exploratory analysis\n",
    "## Compare Ordinary Kriging, Universal Kriging, and IDW\n",
    "## Uses training data to perform analysis\n",
    "arcpy.ga.ExploratoryInterpolation(\n",
    "    in_features=\"ElevationPoint90\",\n",
    "    value_field=\"elevation\",\n",
    "    out_cv_table=arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\InterpolationExp\",\n",
    "    out_geostat_layer=None,\n",
    "    interp_methods=\"ORDINARY_KRIGING;UNIVERSAL_KRIGING;IDW\",\n",
    "    comparison_method=\"SINGLE\",\n",
    "    criterion=\"ACCURACY\",\n",
    "    criteria_hierarchy=\"ACCURACY PERCENT #\",\n",
    "    weighted_criteria=\"ACCURACY 1\",\n",
    "    exclusion_criteria=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 8:59:31 PM\",\"Converted C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\5572Lab3\\\\5572Lab3.gdb\\\\InterpolationExp to C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\5572Lab3\\\\database_connection\\\\postgres_connection.sde\\\\InterpolationExp successfully.\",\"Succeeded at Friday, March 15, 2024 8:59:46 PM (Elapsed Time: 15.50 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Logan\\\\Documents\\\\ArcGIS\\\\Projects\\\\5572Lab3\\\\database_connection\\\\postgres_connection.sde'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Push data to remote database\n",
    "arcpy.conversion.TableToGeodatabase(Input_Table=arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\InterpolationExp\", Output_Geodatabase=arcpy.env.workspace + \"\\\\database_connection\\\\postgres_connection.sde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create 3 maps of our 3 interpolation algorithms\n",
    "## IDW\n",
    "### Deterministic simple interpolation, baseline\n",
    "arcpy.ga.IDW(\n",
    "    in_features=\"ElevationPoint90\",\n",
    "    z_field=\"elevation\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\Elevation_IDW\",\n",
    "    cell_size=9000,\n",
    "    power=2,\n",
    "    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=212324.191980094 S_MINOR=212324.191980094 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "    weight_field=None\n",
    ")\n",
    "\n",
    "## Ordinary Kriging\n",
    "### Simplified model with few assumptions\n",
    "with arcpy.EnvManager(scratchWorkspace=arcpy.env.workspace + \"\\\\5572Lab3.gdb\"):\n",
    "    Elevation_OrdinaryKriging = arcpy.sa.Kriging(\n",
    "        in_point_features=\"ElevationPoint90\",\n",
    "        z_field=\"elevation\",\n",
    "        kriging_model=\"Spherical # # # #\",\n",
    "        cell_size=9000,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "        out_variance_prediction_raster=None\n",
    "    )\n",
    "    Elevation_OrdinaryKriging.save(arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\Elevation_OrdinaryKriging\")\n",
    "    \n",
    "## Universal Kriging\n",
    "### Models the underlying data, more complex\n",
    "### This has highest accuracy in our model\n",
    "with arcpy.EnvManager(scratchWorkspace=arcpy.env.workspace + \"\\\\5572Lab3.gdb\"):\n",
    "    Elevation_UniversalKriging = arcpy.sa.Kriging(\n",
    "        in_point_features=\"ElevationPoint90\",\n",
    "        z_field=\"elevation\",\n",
    "        kriging_model=\"LinearDrift 2196.000000 # # #\",\n",
    "        cell_size=9000,\n",
    "        search_radius=\"VARIABLE 12\",\n",
    "        out_variance_prediction_raster=None\n",
    "    )\n",
    "    Elevation_UniversalKriging.save(arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\Elevation_UniversalKriging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Push to database\n",
    "##Function to convert data to point, then push the point data to the database\n",
    "def point_and_push(data_name, local_gdb_path, geodatabase_path):\n",
    "    \n",
    "    #Convert raster to point data (shape)\n",
    "    arcpy.conversion.RasterToPoint(\n",
    "        in_raster=local_gdb_path + '\\\\' + data_name,\n",
    "        out_point_features=local_gdb_path + '\\\\' + data_name + '_point',\n",
    "        raster_field=\"Value\"\n",
    "    )\n",
    "\n",
    "    print(data_name + ' converted to point')\n",
    "    \n",
    "    #Push data to remote database\n",
    "    arcpy.conversion.FeatureClassToGeodatabase(local_gdb_path + '\\\\' + data_name + '_point', geodatabase_path)\n",
    "    print(local_gdb_path + '\\\\' + data_name + '_point' + ' pushed to database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation_IDW converted to point\n",
      "C:\\Users\\Logan\\Documents\\ArcGIS\\Projects\\5572Lab3\\5572Lab3.gdb\\Elevation_IDW_point pushed to database\n",
      "Elevation_OrdinaryKriging converted to point\n",
      "C:\\Users\\Logan\\Documents\\ArcGIS\\Projects\\5572Lab3\\5572Lab3.gdb\\Elevation_OrdinaryKriging_point pushed to database\n",
      "Elevation_UniversalKriging converted to point\n",
      "C:\\Users\\Logan\\Documents\\ArcGIS\\Projects\\5572Lab3\\5572Lab3.gdb\\Elevation_UniversalKriging_point pushed to database\n"
     ]
    }
   ],
   "source": [
    "#Pushing three interpolation algorithms to database\n",
    "local_gdb_path = arcpy.env.workspace + \"\\\\5572Lab3.gdb\"\n",
    "#Remote database file\n",
    "geodatabase_path = arcpy.env.workspace + \"\\\\database_connection\\\\postgres_connection.sde\"\n",
    "\n",
    "data_name = \"Elevation_IDW\"\n",
    "point_and_push(data_name, local_gdb_path, geodatabase_path)\n",
    "\n",
    "data_name = \"Elevation_OrdinaryKriging\"\n",
    "point_and_push(data_name, local_gdb_path, geodatabase_path)\n",
    "\n",
    "data_name = \"Elevation_UniversalKriging\"\n",
    "point_and_push(data_name, local_gdb_path, geodatabase_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Assessment\n",
    "\n",
    "Perform accuracy assessment on the testing 10% of data compared to our most accuracte interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "Failed to execute. Parameters are not valid.\nERROR 000732: Input Features: Dataset C:\\Users\\Logan\\Documents\\ArcGIS\\Projects\\5572Lab3\\5572Lab3.gdb\\5572Lab3.gdb\\ElevationPoint10 does not exist or is not supported\nFailed to execute (CopyFeatures).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[1]\u001b[0m:\nLine \u001b[0;34m9\u001b[0m:     arcpy.CopyFeatures_management(input_point_dataset, output_point_dataset)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m, in \u001b[0;32mCopyFeatures\u001b[0m:\nLine \u001b[0;34m4203\u001b[0m:  \u001b[34mraise\u001b[39;49;00m e\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m, in \u001b[0;32mCopyFeatures\u001b[0m:\nLine \u001b[0;34m4200\u001b[0m:  retval = convertArcObjectToPythonObject(gp.CopyFeatures_management(*gp_fixargs((in_features, out_feature_class, config_keyword, spatial_grid_1, spatial_grid_2, spatial_grid_3), \u001b[34mTrue\u001b[39;49;00m)))\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m520\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mExecuteError\u001b[0m: Failed to execute. Parameters are not valid.\nERROR 000732: Input Features: Dataset C:\\Users\\Logan\\Documents\\ArcGIS\\Projects\\5572Lab3\\5572Lab3.gdb\\5572Lab3.gdb\\ElevationPoint10 does not exist or is not supported\nFailed to execute (CopyFeatures).\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Our testing data (10% sample)\n",
    "input_point_dataset = arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\ElevationPoint10\"\n",
    "#Best interpolation\n",
    "input_raster = arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\Elevation_UniversalKriging\"\n",
    "#Store results\n",
    "output_point_dataset = arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\Elevation_Accuracy\"\n",
    "\n",
    "#Copy the point dataset\n",
    "arcpy.CopyFeatures_management(input_point_dataset, output_point_dataset)\n",
    "\n",
    "#Pull raster values to the copied points dataset\n",
    "#Name of field in interpolated raster data that we are pulling from\n",
    "extracted_field_name = \"VALUE\"\n",
    "#Pulling these values into the copied dataset\n",
    "arcpy.sa.ExtractValuesToPoints(input_point_dataset, input_raster, output_point_dataset,\n",
    "                               \"INTERPOLATE\", \"VALUE_ONLY\")\n",
    "\n",
    "#Names of columns\n",
    "## elevation (the testing data)\n",
    "## RASTERVALU (The interpolation data we pulled)\n",
    "## Diff_Value (new field that is elevation minus RASTERVALU)\n",
    "point_value_field = \"elevation\"\n",
    "difference_field = \"Diff_Value\"\n",
    "extracted_field_name = \"RASTERVALU\"\n",
    "\n",
    "#Add a new field for the difference\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=\"Elevation_Accuracy\",\n",
    "    field=\"Diff_Value\",\n",
    "    expression=\"!elevation!-!RASTERVALU!\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"LONG\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    ")\n",
    "\n",
    "print(\"Process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushed to database\n"
     ]
    }
   ],
   "source": [
    "#push elevation_accuracy to database    \n",
    "arcpy.conversion.FeatureClassToGeodatabase(arcpy.env.workspace + \"\\\\5572Lab3.gdb\\\\Elevation_Accuracy\", arcpy.env.workspace + \"\\\\database_connection\\\\postgres_connection.sde\")\n",
    "print('pushed to database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
